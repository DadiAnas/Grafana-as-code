# Grafana Alert Rules Configuration - NPR Environment
# These override or extend shared alert rules for NPR

alert_rules:
  # Main Organization alerts (default org)
  - name: "High CPU Usage"
    folder: "alerts"
    org: "Main Organization"
    rule_group: "Infrastructure"
    condition: "C"
    for: "5m"
    # NEW PARAMETERS FOR TESTING
    no_data_state: "OK"
    exec_err_state: "Alerting"
    is_paused: false
    annotations:
      summary: "High CPU usage detected"
      description: "CPU usage is above 80% for more than 5 minutes"
      runbook_url: "https://wiki.example.com/runbooks/high-cpu"
    labels:
      severity: "warning"
      team: "platform"
    data:
      - ref_id: "A"
        datasource_uid: "prometheus"
        model:
          expr: "100 - (avg by(instance) (irate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100)"
          interval: ""
          legendFormat: "{{instance}}"
      - ref_id: "B"
        datasource_uid: "__expr__"
        model:
          type: "reduce"
          expression: "A"
          reducer: "mean"
      - ref_id: "C"
        datasource_uid: "__expr__"
        model:
          type: "threshold"
          expression: "B"
          conditions:
            - evaluator:
                type: "gt"
                params: [80]

  - name: "High Memory Usage"
    folder: "alerts"
    org: "Main Organization"
    rule_group: "Infrastructure"
    condition: "C"
    for: "5m"
    annotations:
      summary: "High memory usage detected"
      description: "Memory usage is above 85%"
    labels:
      severity: "warning"
      team: "platform"
    data:
      - ref_id: "A"
        datasource_uid: "prometheus"
        model:
          expr: "(1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100"
      - ref_id: "B"
        datasource_uid: "__expr__"
        model:
          type: "reduce"
          expression: "A"
          reducer: "mean"
      - ref_id: "C"
        datasource_uid: "__expr__"
        model:
          type: "threshold"
          expression: "B"
          conditions:
            - evaluator:
                type: "gt"
                params: [85]

  - name: "Disk Space Low"
    folder: "alerts"
    org: "Main Organization"
    rule_group: "Infrastructure"
    condition: "C"
    for: "10m"
    annotations:
      summary: "Low disk space"
      description: "Disk usage is above 90%"
    labels:
      severity: "critical"
      team: "platform"
    data:
      - ref_id: "A"
        datasource_uid: "prometheus"
        model:
          expr: "(1 - (node_filesystem_avail_bytes / node_filesystem_size_bytes)) * 100"
      - ref_id: "B"
        datasource_uid: "__expr__"
        model:
          type: "reduce"
          expression: "A"
          reducer: "max"
      - ref_id: "C"
        datasource_uid: "__expr__"
        model:
          type: "threshold"
          expression: "B"
          conditions:
            - evaluator:
                type: "gt"
                params: [90]

  # Application alerts
  - name: "High Error Rate"
    folder: "alerts"
    org: "Main Organization"
    rule_group: "Applications"
    condition: "C"
    for: "2m"
    annotations:
      summary: "High error rate detected"
      description: "Error rate is above 5%"
    labels:
      severity: "critical"
      team: "backend"
    data:
      - ref_id: "A"
        datasource_uid: "prometheus"
        model:
          expr: "sum(rate(http_requests_total{status=~\"5..\"}[5m])) / sum(rate(http_requests_total[5m])) * 100"
      - ref_id: "B"
        datasource_uid: "__expr__"
        model:
          type: "reduce"
          expression: "A"
          reducer: "mean"
      - ref_id: "C"
        datasource_uid: "__expr__"
        model:
          type: "threshold"
          expression: "B"
          conditions:
            - evaluator:
                type: "gt"
                params: [5]

  - name: "High Latency"
    folder: "alerts"
    org: "Main Organization"
    rule_group: "Applications"
    condition: "C"
    for: "5m"
    annotations:
      summary: "High latency detected"
      description: "P99 latency is above 1 second"
    labels:
      severity: "warning"
      team: "backend"
    data:
      - ref_id: "A"
        datasource_uid: "prometheus"
        model:
          expr: "histogram_quantile(0.99, sum(rate(http_request_duration_seconds_bucket[5m])) by (le))"
      - ref_id: "B"
        datasource_uid: "__expr__"
        model:
          type: "reduce"
          expression: "A"
          reducer: "mean"
      - ref_id: "C"
        datasource_uid: "__expr__"
        model:
          type: "threshold"
          expression: "B"
          conditions:
            - evaluator:
                type: "gt"
                params: [1]
